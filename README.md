# â›ï¸ Minecraft agent player for [ã‚¢ã‚¤ãƒª (AIRI)](https://airi.moeru.ai)

> [!NOTE]
>
> This project is part of the [Project ã‚¢ã‚¤ãƒª (AIRI)](https://github.com/moeru-ai/airi), we aim to build a LLM-driven VTuber like [Neuro-sama](https://www.youtube.com/@Neurosama) (subscribe if you didn't!) if you are interested in, please do give it a try on [live demo](https://airi.moeru.ai).

An intelligent Minecraft bot powered by LLM. AIRI can understand natural language commands, interact with the world, and assist players in various tasks.

## ğŸ¥ Preview

![demo](./docs/preview.avif)

## âœ¨ Features

- ğŸ—£ï¸ Natural language understanding
- ğŸƒâ€â™‚ï¸ Advanced pathfinding and navigation
- ğŸ› ï¸ Block breaking and placing
- ğŸ¯ Combat and PvP capabilities
- ğŸ”„ Auto-reconnect on disconnection
- ğŸ“¦ Inventory management
- ğŸ¤ Player following and interaction
- ğŸŒ World exploration and mapping

## ğŸš€ Getting Started

### ğŸ“‹ Prerequisites

- ğŸ“¦ Node.js 23+
- ğŸ”§ pnpm
- ğŸ® A Minecraft server (1.20+)

### ğŸ”¨ Installation

1. Clone the repository:

```bash
git clone https://github.com/moeru-ai/airi.git
cd services/minecraft
```

2. Install dependencies:

```bash
pnpm install
```

3. Create a `.env.local` file with your configuration:

> [!NOTE]
> For all online accounts, un-comment the following line to toggle Microsoft authentication.
> Link for authentication will popup when the bot starts.
>
> After signed in, according to [how Minecraft protocol was implemented](https://github.com/PrismarineJS/node-minecraft-protocol/blob/bf89f7e86526c54d8c43f555d8f6dfa4948fd2d9/src/client/microsoftAuth.js#L7-L16)
> and also, [authentication flow implemented here](https://github.com/PrismarineJS/prismarine-auth/blob/1aef6e1387d94fca839f2811d17ac6659ae556b4/src/MicrosoftAuthFlow.js#L59-L69),
> the token will be cached with [the cache IDs specified here](https://github.com/PrismarineJS/prismarine-auth/blob/1aef6e1387d94fca839f2811d17ac6659ae556b4/src/MicrosoftAuthFlow.js#L88-L93)
> in split files:
>
> - `${hash}_live-cache.json`
> - `${hash}_mca-cache.json`
> - `${hash}_xbl-cache.json`
>
> inside of the directory provided by [`minecraft-folder-path`](https://github.com/simonmeusel/minecraft-folder-path)
>
> Linux: `~/.minecraft/nmp-cache/`
> macOS: `~/Library/Application Support/minecraft/nmp-cache/`
> Windows: `%appdata%/.minecraft/nmp-cache/`
>
> where `${hash}` is the `sha1` hash of the username you signing in with (as Minecraft username).

```env
OPENAI_API_KEY=your_openai_api_key
OPENAI_API_BASEURL=your_openai_api_baseurl

BOT_USERNAME=your_bot_username
BOT_HOSTNAME=localhost
BOT_PORT=25565
BOT_AUTH='microsoft' # comment if you use offline mode
BOT_VERSION=1.20
```

1. Start the bot:

```bash
pnpm dev
```

## ğŸ® Usage

Once the bot is connected, you can interact with it using chat commands in Minecraft. All commands start with `#`.

### Basic Commands

- `#help` - Show available commands
- `#follow` - Make the bot follow you
- `#stop` - Stop the current action
- `#come` - Make the bot come to your location

### Natural Language Commands

You can also give the bot natural language commands, and it will try to understand and execute them. For example:

- "Build a house"
- "Find some diamonds"
- "Help me fight these zombies"
- "Collect wood from nearby trees"

## ğŸ§  Cognitive Architecture

AIRI's Minecraft agent is built on a **four-layered cognitive architecture** inspired by cognitive science, enabling reactive, conscious, and physically grounded behaviors.

### Architecture Overview

```mermaid
graph TB
    subgraph "Layer A: Perception"
        Events[Raw Events]
        EM[Event Manager]
        Events --> EM
    end

    subgraph "Layer B: Reflex (Subconscious)"
        RM[Reflex Manager]
        FSM[State Machine]
        RM --> FSM
    end

    subgraph "Layer C: Conscious (Reasoning)"
        ORC[Orchestrator]
        Planner[Planning Agent (LLM)]
        Chat[Chat Agent (LLM)]
        ORC --> Planner
        ORC --> Chat
    end

    subgraph "Layer D: Action (Execution)"
        TE[Task Executor]
        AA[Action Agent]
        Planner -->|Plan| TE
        TE -->|Action Steps| AA
    end

    EM -->|High Priority| RM
    EM -->|All Events| ORC
    RM -.->|Inhibition Signal| ORC
    ORC -->|Execution Request| TE

    style EM fill:#e1f5ff
    style RM fill:#fff4e1
    style ORC fill:#ffe1f5
    style TE fill:#dcedc8
```

### Layer A: Perception

**Location**: `src/cognitive/perception/`

The perception layer acts as the sensory input hub, receiving and preprocesses all events from the Minecraft world and external sources.

**Components**:
- **Event Manager** (`event-manager.ts`): Centralized event distribution system
  - Emits standardized `BotEvent` objects
  - Supports event prioritization and concurrency

### Layer B: Reflex

**Location**: `src/cognitive/reflex/`

The reflex layer handles immediate, instinctive reactions. It operates on a finite state machine (FSM) pattern for predictable, fast responses.

**Components**:
- **Reflex Manager** (`reflex-manager.ts`): Coordinates reflex behaviors
- **Inhibition**: Reflexes can inhibit Conscious layer processing to prevent redundant responses.

### Layer C: Conscious

**Location**: `src/cognitive/conscious/`

The conscious layer handles complex reasoning, planning, and high-level decision-making. No physical execution happens here anymore.

**Components**:
- **Orchestrator**: Coordinates "Thinking" vs "Chatting" tasks.
- **Task Manager**: Manages concurrent Primary (Physical) and Secondary (Mental) tasks.
- **Planning Agent**: pure LLM reasoning to generate plans.
- **Chat Agent**: Generates natural language responses.

### Layer D: Action

**Location**: `src/cognitive/action/`

The action layer is responsible for the actual execution of tasks in the world. It isolates "Doing" from "Thinking".

**Components**:
- **Task Executor**: Receives a `Plan` and executes it step-by-step. Handles retry logic and errors.
- **Action Agent**: The interface to low-level Mineflayer skills (move, place, break).

### ğŸ”„ Event Flow Example

**Scenario: "Build a house"**
```
Player: "build a house"
  â†“
[Perception] Event detected
  â†“
[Conscious] Architect plans the structure
  â†“
[Action] Executor takes the plan and manages the construction loop:
    - Step 1: Collect wood (calls ActionAgent)
    - Step 2: Craft planks
    - Step 3: Build walls
  â†“
[Conscious] ChatAgent confirms completion: "House is ready!"
```

### ğŸ“ Project Structure

```
src/
â”œâ”€â”€ cognitive/                  # ğŸ§  Perception â†’ Reflex â†’ Conscious â†’ Action
â”‚   â”œâ”€â”€ perception/            # Event ingestion
â”‚   â”‚   â””â”€â”€ event-manager.ts   # Normalizes raw Mineflayer events
â”‚   â”œâ”€â”€ reflex/                # Fast, rule-based reactions
â”‚   â”‚   â””â”€â”€ reflex-manager.ts
â”‚   â”œâ”€â”€ conscious/             # LLM-powered reasoning
â”‚   â”‚   â”œâ”€â”€ blackboard.ts      # Shared working memory
â”‚   â”‚   â”œâ”€â”€ brain.ts           # Core reasoning loop/orchestration
â”‚   â”‚   â”œâ”€â”€ completion.ts      # LLM completion helper
â”‚   â”‚   â”œâ”€â”€ handler.ts         # Routes stimuli into the brain
â”‚   â”‚   â”œâ”€â”€ task-manager.ts    # Manages concurrent tasks
â”‚   â”‚   â”œâ”€â”€ task-state.ts      # Task lifecycle enums/helpers
â”‚   â”‚   â””â”€â”€ prompts/           # Prompt definitions (e.g., brain-prompt.ts)
â”‚   â”œâ”€â”€ action/                # Task execution layer
â”‚   â”‚   â”œâ”€â”€ task-executor.ts   # Executes planned steps with retries
â”‚   â”‚   â””â”€â”€ types.ts
â”‚   â”œâ”€â”€ container.ts           # Dependency injection wiring
â”‚   â”œâ”€â”€ index.ts               # Cognitive system entrypoint
â”‚   â””â”€â”€ types.ts               # Shared cognitive types
â”œâ”€â”€ agents/                    # Specialized agents
â”‚   â”œâ”€â”€ action/               # Low-level actuator bridge
â”‚   â”œâ”€â”€ planning/             # Goal planner (LLM)
â”‚   â”œâ”€â”€ chat/                 # Conversational responses
â”‚   â””â”€â”€ memory/               # Memory-related helpers
â”œâ”€â”€ libs/
â”‚   â””â”€â”€ mineflayer/           # Mineflayer bot wrapper/adapters
â”œâ”€â”€ skills/                   # Atomic bot capabilities
â”œâ”€â”€ composables/              # Reusable functions (config, etc.)
â”œâ”€â”€ plugins/                  # Mineflayer/bot plugins
â”œâ”€â”€ web/                      # Debug web dashboard
â”œâ”€â”€ utils/                    # Helpers
â”œâ”€â”€ debug-server.ts           # Local debug server entry
â””â”€â”€ main.ts                   # Bot entrypoint
```

### ğŸ¯ Design Principles

1. **Separation of Concerns**: Each layer has a distinct responsibility
2. **Event-Driven**: Loose coupling via centralized event system
3. **Inhibition Control**: Reflexes prevent unnecessary LLM calls
4. **Extensibility**: Easy to add new reflexes or conscious behaviors
5. **Cognitive Realism**: Mimics human-like perception â†’ reaction â†’ deliberation

### ğŸš§ Future Enhancements

- **Perception Layer**:
  - â±ï¸ Temporal context window (remember recent events)
  - ğŸ¯ Salience detection (filter noise, prioritize important events)

- **Reflex Layer**:
  - ğŸƒ Dodge hostile mobs
  - ğŸ– Auto-eat when health/hunger is low
  - ğŸ›¡ï¸ Emergency combat responses

- **Conscious Layer**:
  - ğŸ’­ Emotional state management
  - ğŸ§  Long-term memory integration
  - ğŸ­ Personality-driven responses

## ğŸ› ï¸ Development

### Commands

- `pnpm dev` - Start the bot in development mode
- `pnpm lint` - Run ESLint
- `pnpm typecheck` - Run TypeScript type checking
- `pnpm test` - Run tests

## ğŸ™ Acknowledgements

- https://github.com/kolbytn/mindcraft

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.
